{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of these imports might not be needed\n",
    "# im too lazy to remove them\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the net\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 32x32 at the start because input is single channel images of\n",
    "        # size: 32x32\n",
    "        self.fc1 = nn.Linear(32*32, 16)\n",
    "        # single hidden layer\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        # 3 classes on the output (square / triangle / x shape)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is a flattened version of the single channel image\n",
    "        display_layer(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        display_layer(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        display_layer(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        display_layer(x.unsqueeze(0), square_image=False)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "# remove these two lines if you dont have CUDA / GPU available\n",
    "GPU = torch.device(\"cuda\")\n",
    "net.to(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initian learning rate is the learning rate at the start of the training\n",
    "# (it changes every epoch)\n",
    "initlr = 0.001\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=initlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used to load images from a directory into batches later in the dataset class\n",
    "def load_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert(\"L\")\n",
    "    img_array = np.array(img) / 255\n",
    "\n",
    "    return torch.tensor(img_array, dtype=torch.float32, device=GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in an input, output, and network and trains it\n",
    "def train_nn(question_tensor, answer_tensor, model, loss=loss, optimizer=optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(question_tensor)\n",
    "    loss = loss(outputs, answer_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used to later visualize the layers\n",
    "def display_layer(layer, square_image=True):\n",
    "    layer = layer.detach().cpu()\n",
    "    if square_image:\n",
    "        side_length = int(np.sqrt(len(layer)))\n",
    "        layer = np.reshape(layer, (side_length, side_length))\n",
    "        plt.imshow(layer)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.imshow(layer)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this goes over a test dataset/loader and returns the number of errors the network made\n",
    "def test_network(net, dataloader):\n",
    "    errors = 0\n",
    "    \n",
    "    for x in enumerate(dataloader):\n",
    "        if torch.argmax(x[1][1]) != torch.argmax(net(x[1][0])):\n",
    "            errors += 1\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this mf takes in a directory and returns a ready dataset with images as inputs, and onehot encoded labels on the other\n",
    "class ImageDataset():\n",
    "    def __init__(self, main_dir):\n",
    "        self.questions = []\n",
    "        self.answers = []\n",
    "        \n",
    "        self.class_folders = os.listdir(main_dir)\n",
    "        \n",
    "        for x in tqdm(range(len(self.class_folders))):\n",
    "            self.current_dir = os.listdir(f\"{main_dir}/{self.class_folders[x]}\")\n",
    "            \n",
    "            for y in self.current_dir:\n",
    "                self.questions.append(load_image(f\"{main_dir}/{self.class_folders[x]}/{y}\").flatten())\n",
    "                self.answers.append(torch.eye(len(self.class_folders), device=GPU)[x])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.questions[idx], self.answers[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 96.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#                              both assume that the\n",
    "#                      dataset is in the same dir as this file\n",
    "#                                       |\n",
    "#                                       V\n",
    "train_dataset = ImageDataset(r\".\\img_dataset\\train\")\n",
    "test_dataset = ImageDataset(r\".\\img_dataset\\test\")\n",
    "\n",
    "#                                       the dataset is so small that\n",
    "#                                       i can fit it whole on my GPU\n",
    "#                                                    |\n",
    "#                                                    V\n",
    "train_loader = DataLoader(train_dataset, batch_size=999, shuffle=True)\n",
    "#                          the batch size here HAS to remain 1 because if not \n",
    "#                       it causes problems with the argmax in the test_net() func\n",
    "#                                                 |\n",
    "#                                                 V\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3702.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# you can plot the lists if you want\n",
    "# mine (from the vid) are somewhere in the repo\n",
    "# everything is commented so i dont have to wait every time i restart the notebook\n",
    "loss_list = []\n",
    "error_list = []\n",
    "lr_list = []\n",
    "epochs = 100\n",
    "lr_decent_rate = 0.005\n",
    "\n",
    "for y in tqdm(range(epochs)):\n",
    "    for x in enumerate(train_loader):\n",
    "        #loss_list.append(train_nn(x[1][0], x[1][1], net))\n",
    "        #error_list.append(test_network(net, test_loader))\n",
    "        pass\n",
    "    \n",
    "    #lr = initlr * (lr_decent_rate ** (y/epochs))\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    #lr_list.append(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), fr\"xts_classifier_{100 - test_network(net, test_loader) / len(test_dataset) * 100:.03f}%acc.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(r\".\\xts_classifier_80.000%acc.pth\")\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAIN_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
